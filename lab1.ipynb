{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a5b65f",
   "metadata": {
    "id": "60a5b65f"
   },
   "source": [
    "# Machine Learning Fundamentals Workshop\n",
    "\n",
    "Welcome! This notebook guides you through practical exercises in `Python, NumPy, Pandas, Matplotlib, and scikit-learn`.  \n",
    "Follow each section, run the code cells, and complete the exercises to build your ML skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1f548",
   "metadata": {
    "id": "83f1f548"
   },
   "source": [
    "## 1. Python & NumPy Basics\n",
    "\n",
    "NumPy is the foundation for numerical computing in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dafbf36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1752456175764,
     "user": {
      "displayName": "Nguyen Dinh Hieu",
      "userId": "10658243561888199871"
     },
     "user_tz": -420
    },
    "id": "9dafbf36",
    "outputId": "b2cebc43-e7bc-48d1-887b-35f976efab49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: [1 2 3 4 5]\n",
      "Mean: 3.0\n",
      "Standard Deviation: 1.4142135623730951\n",
      "Matrix:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Column sums: [12 15 18]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 1D array\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(\"Array:\", arr)\n",
    "print(\"Mean:\", np.mean(arr))\n",
    "print(\"Standard Deviation:\", np.std(arr))\n",
    "\n",
    "# Exercise: Create a 3x3 matrix and calculate the sum of each column.\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"Matrix:\\n\", matrix)\n",
    "print(\"Column sums:\", np.sum(matrix, axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7baa46",
   "metadata": {
    "id": "be7baa46"
   },
   "source": [
    "## 2. Pandas for Data Analysis\n",
    "\n",
    "Pandas makes working with tabular data easy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3b274",
   "metadata": {
    "id": "28f3b274"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset (from seaborn for simplicity)\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "print(titanic.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(titanic.isnull().sum())\n",
    "\n",
    "# Exercise: Count unique values in the 'embarked' column and fill missing values with the mode.\n",
    "print(\"Unique Embarked:\", titanic['embarked'].unique())\n",
    "titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b26695",
   "metadata": {
    "id": "e6b26695"
   },
   "source": [
    "## 3. Data Visualization\n",
    "\n",
    "Matplotlib helps visualize data distributions and relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0c9b7",
   "metadata": {
    "id": "7fe0c9b7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3330d21",
   "metadata": {
    "id": "b3330d21"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram of passenger age\n",
    "plt.hist(titanic['age'].dropna(), bins=20, color='skyblue')\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Exercise: Create a scatter plot of 'fare' vs 'age'.\n",
    "plt.scatter(titanic['age'], titanic['fare'], alpha=0.5)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Fare')\n",
    "plt.title('Fare vs Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e7ef2c",
   "metadata": {
    "id": "91e7ef2c"
   },
   "source": [
    "## Exercise 1:\n",
    "A. `Numpy` exercise\n",
    "1. Create and Manipulate Arrays\n",
    "- Create a 1D NumPy array of numbers from 0 to 9.\n",
    "- Reshape it into a 2D array with 2 rows.\n",
    "- Calculate the sum of all elements and the mean of each row.\n",
    "\n",
    "2. Array Slicing and Indexing\n",
    "- Given an array arr = np.arange(20), extract all even numbers.\n",
    "- Replace all values greater than 10 with -1.\n",
    "\n",
    "3. Mathematical Operations\n",
    "- Generate a 3x3 matrix of random integers between 1 and 10.\n",
    "- Compute the element-wise square of the matrix.\n",
    "- Find the maximum value in each column.\n",
    "\n",
    "B. `Pandas` exercise\n",
    "1. DataFrame Creation and Exploration\n",
    "- Create a DataFrame with columns: Name, Age, Score.\n",
    "- Add at least 5 rows of sample data.\n",
    "- Display summary statistics and check for missing values.\n",
    "\n",
    "2. Data Selection and Filtering\n",
    "- From the DataFrame above, select all rows where Score is greater than 80.\n",
    "- Add a new column called Passed that is True if Score ≥ 60, else False.\n",
    "\n",
    "3. Data Cleaning\n",
    "- Introduce some missing values in the Age column.\n",
    "- Fill missing ages with the mean age.\n",
    "- Remove any duplicate rows from the DataFrame.\n",
    "\n",
    "C. `Matplotlib` exercise\n",
    "1. Basic Plotting\n",
    "- Plot a line graph showing the squares of numbers from 0 to 10.\n",
    "- Add axis labels and a title.\n",
    "\n",
    "2. Histogram\n",
    "- Plot a line graph showing the squares of numbers from 0 to 10.\n",
    "- Add axis labels and a title.\n",
    "\n",
    "3. Scatter plot\n",
    "- Use the Pandas `DataFrame` from earlier.\n",
    "- Plot a scatter plot of `Age` vs. `Score`.\n",
    "- Color points by the value in the Passed column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555efc46",
   "metadata": {
    "id": "555efc46"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3bca3c",
   "metadata": {
    "id": "1b3bca3c"
   },
   "source": [
    "## 4. Linear Regression Example (Diabetes Dataset)\n",
    "\n",
    "Linear regression predicts continuous values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c57db",
   "metadata": {
    "id": "da2c57db"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "#Load and inspect\n",
    "cal = fetch_california_housing(as_frame=True)\n",
    "X, y = cal.data, cal.target * 100_000        # convert to dollars for readability\n",
    "\n",
    "#Train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Fit\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE :\", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE :\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R²  :\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312915f3",
   "metadata": {
    "id": "312915f3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Compute residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# 2. Residual-vs-Predicted scatter plot\n",
    "plt.figure(figsize=(7,4))\n",
    "# code here\n",
    "plt.show()\n",
    "\n",
    "# 3. Histogram (and KDE) of residuals\n",
    "plt.figure(figsize=(7,4))\n",
    "# code here\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d173c",
   "metadata": {
    "id": "759d173c"
   },
   "source": [
    "## 5. Logistic Regression Example (Iris Dataset)\n",
    "\n",
    "Logistic regression is used for classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825a16e",
   "metadata": {
    "id": "7825a16e"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Exercise: Change test_size to 0.3 and observe the effect on accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357358c4",
   "metadata": {
    "id": "357358c4"
   },
   "source": [
    "## Exercise 2 - Mini Project\n",
    "\n",
    "A. [Abalone Dataset](https://www.kaggle.com/datasets/rodolfomendes/abalone-dataset) — Regression Task\n",
    "\n",
    "1.  Project Overview:\n",
    "\n",
    "- Goal: Predict the age of abalone (number of rings) based on physical measurements.\n",
    "- Task Type: Regression\n",
    "- Dataset Source: UCI Machine Learning Repository\n",
    "\n",
    "1.  Dataset Features\n",
    "- Sex: Categorical (M, F, I)\n",
    "- Length, Diameter, Height: Numeric (physical measurements)\n",
    "- Whole weight, Shucked weight, Viscera weight, Shell weight: Numeric (weights in grams)\n",
    "- Rings: Integer (target variable; age = rings + 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efccae53",
   "metadata": {
    "id": "efccae53"
   },
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 2. Load the Abalone dataset\n",
    "\n",
    "\n",
    "# 3. Data preprocessing\n",
    "# Encode categorical 'Sex' feature using OneHotEncoder\n",
    "\n",
    "\n",
    "# 4. Define features and target\n",
    "\n",
    "\n",
    "# 5. Split data into training and test sets\n",
    "\n",
    "\n",
    "# 6. Feature scaling (optional but recommended for regression)\n",
    "\n",
    "\n",
    "# 7. Train a Linear Regression model\n",
    "\n",
    "\n",
    "# 8. Make predictions and evaluate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77257cd",
   "metadata": {
    "id": "d77257cd"
   },
   "source": [
    "B. [Breast Cancer Wisconsin (Diagnostic)](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data) — Classification Task\n",
    "1. Project Overview\n",
    "- Goal: Predict whether a tumor is malignant or benign based on cell features.\n",
    "- Task Type: Classification\n",
    "- Dataset Source: Built into scikit-learn\n",
    "\n",
    "2. Dataset Features\n",
    "- 30 numeric features (mean, standard error, and worst of various cell characteristics)\n",
    "- Target: Diagnosis (0 = malignant, 1 = benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b6075",
   "metadata": {
    "id": "1f8b6075"
   },
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Load the Breast Cancer Wisconsin dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "\n",
    "# 3. Convert to DataFrame for exploration (optional)\n",
    "\n",
    "\n",
    "# 4. Train/test split\n",
    "\n",
    "\n",
    "# 5. Feature scaling (recommended)\n",
    "\n",
    "\n",
    "# 6. Train a Logistic Regression model\n",
    "\n",
    "\n",
    "# 7. Make predictions and evaluate\n",
    "\n",
    "\n",
    "# 8. Exercise: Try other classifiers (e.g., DecisionTreeClassifier, RandomForestClassifier, SVC)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (venv_nvidia)",
   "language": "python",
   "name": "venv_nvidiaproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
